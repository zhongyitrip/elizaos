/**
 * æµ‹è¯• Ollama çš„ OpenAI å…¼å®¹ API æ˜¯å¦æ­£å¸¸å·¥ä½œ
 */

async function testOllamaAPI() {
  console.log('ğŸ” æµ‹è¯• Ollama OpenAI å…¼å®¹ API...\n');
  
  const baseURL = 'http://127.0.0.1:11434/v1';
  const model = 'qwen3-vl:4b';
  
  console.log(`   - Endpoint: ${baseURL}`);
  console.log(`   - Model: ${model}`);
  console.log('');

  try {
    console.log('ğŸ“¤ å‘é€æµ‹è¯•è¯·æ±‚...');
    
    const response = await fetch(`${baseURL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: model,
        messages: [
          {
            role: 'user',
            content: [
              {
                type: 'text',
                text: 'è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±'
              }
            ]
          }
        ],
        max_tokens: 100,
        temperature: 0.7
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`HTTP ${response.status}: ${errorText}`);
    }

    const data = await response.json();
    
    console.log('âœ… Ollama API å“åº”æˆåŠŸï¼\n');
    console.log('ğŸ¤– æ¨¡å‹å›å¤:');
    console.log('   ' + data.choices[0].message.content);
    console.log('\nğŸ“Š ä½¿ç”¨ç»Ÿè®¡:');
    console.log(`   - Prompt Tokens: ${data.usage?.prompt_tokens || 'N/A'}`);
    console.log(`   - Completion Tokens: ${data.usage?.completion_tokens || 'N/A'}`);
    console.log(`   - Total Tokens: ${data.usage?.total_tokens || 'N/A'}`);
    
    console.log('\nğŸ‰ Ollama OpenAI å…¼å®¹ API å·¥ä½œæ­£å¸¸ï¼');
    console.log('ğŸ’¡ ç°åœ¨å¯ä»¥ç”¨äº Midscene é›†æˆäº†');
    
  } catch (error) {
    console.error('\nâŒ æµ‹è¯•å¤±è´¥:', error);
    console.log('\nğŸ’¡ æ•…éšœæ’æŸ¥:');
    console.log('   1. ç¡®è®¤ Ollama æœåŠ¡è¿è¡Œ: ollama serve');
    console.log('   2. ç¡®è®¤æ¨¡å‹å·²å®‰è£…: ollama list | grep qwen3-vl');
    console.log('   3. æ£€æŸ¥ç«¯å£: curl http://127.0.0.1:11434/api/tags');
  }
}

testOllamaAPI().catch(console.error);
