import type { IAgentRuntime } from '@elizaos/core';
import { logger } from '@elizaos/core';

/**
 * Free model pool configuration for OpenRouter
 * Models are ordered by priority (fastest/most reliable first)
 * 
 * âš ï¸ Updated: 2026-01-24 - Optimized for Quality Priority & Smart Fallback
 * 
 * Strategy: "Quality First, Speed Second" (è´¨é‡ä¼˜å…ˆï¼Œå…¼é¡¾é€Ÿåº¦)
 * 1. Always prioritize the BEST model (e.g. Gemma 27B) - æ°¸è¿œä¼˜å…ˆå°è¯•æœ€å¥½çš„æ¨¡å‹
 * 2. Only fallback if the best model is currently Rate Limited (Cool-down) - åªæœ‰æœ€å¥½çš„æ¨¡å‹é™æµäº†æ‰é™çº§
 * 3. Automatically retry the best model after cool-down expires - å†·å´ç»“æŸåç«‹åˆ»åˆ‡å›æœ€å¥½çš„æ¨¡å‹
 * 
 * ğŸ“Š Total: 33 free models available
 * ğŸ“ Run `bun run scripts/query-free-models.ts` to update
 */
export const FREE_MODEL_POOLS = {
    // Small/Fast models for quick responses
    // Priority Order:
    // 1. Gemma 3 27B (Best Balance)
    // 2. Gemini 2.0 Flash (Fastest, High Quality, but strict rate limits)
    // 3. Gemma 3 12B (Safe Backup)
    // 4. Large Models (Power Backup)
    SMALL: [
        'google/gemma-3-27b-it:free',            // Priority 1: High reliability, good speed (ä¸»åŠ›)
        'google/gemini-2.0-flash-exp:free',      // Priority 2: Fastest but rate limited (æé€Ÿ)
        'google/gemma-3-12b-it:free',            // Priority 3: Reliable backup (ç¨³å®šå¤‡ä»½)
        'qwen/qwen3-4b:free',                    // Priority 4: Chinese-friendly (ä¸­æ–‡å‹å¥½)

        // ğŸš€ FALLBACK TO HEAVY HITTERS (Why waste free quota? Use them!)
        // å½“å°æ¨¡å‹å…¨æŒ‚äº†ï¼Œç”¨å¤§æ¨¡å‹é¡¶ä¸Š
        'meta-llama/llama-3.1-405b-instruct:free', // Priority 5: The Beast (Slow but free)
        'meta-llama/llama-3.3-70b-instruct:free',  // Priority 6: Solid & Reliable
        'deepseek/deepseek-r1-0528:free',          // Priority 7: DeepSeek
        'qwen/qwen3-next-80b-a3b-instruct:free',   // Priority 8: Qwen Large
    ],

    // Large/Reasoning models for complex tasks
    LARGE: [
        'meta-llama/llama-3.1-405b-instruct:free', // Priority 1: Best reasoning (405B)
        'meta-llama/llama-3.3-70b-instruct:free',  // Priority 2: General purpose reliable
        'deepseek/deepseek-r1-0528:free',          // Priority 3: DeepSeek reasoning
        'qwen/qwen3-next-80b-a3b-instruct:free',   // Priority 4: Chinese reasoning
        'nousresearch/hermes-3-llama-3.1-405b:free', // Priority 5: Alternative 405B
    ],

    // Vision models for image analysis
    VISION: [
        'google/gemini-2.0-flash-exp:free',      // Priority 1: Best vision context (1M)
        'qwen/qwen-2.5-vl-7b-instruct:free',     // Priority 2: Chinese vision
        'nvidia/nemotron-nano-12b-v2-vl:free',   // Priority 3: NVIDIA vision
        'allenai/molmo-2-8b:free',               // Priority 4: Standard vision
    ],

    // Code generation models
    CODE: [
        'qwen/qwen3-coder:free',                 // Priority 1: Code specialist
        'mistralai/devstral-2512:free',          // Priority 2: Development tasks
        'deepseek/deepseek-r1-0528:free',        // Priority 3: Code reasoning
    ],
} as const;

// Rate Limit Tracker (é™æµè¿½è¸ªå™¨)
// Maps modelName -> timestamp (when it was last rate limited)
// è®°å½•æ¯ä¸ªæ¨¡å‹æœ€åä¸€æ¬¡æŠ¥é”™çš„æ—¶é—´
const rateLimitCoolDowns: Record<string, number> = {};

// Cool-down duration in milliseconds (e.g., 60 seconds)
// After this time, we will try the model again even if it failed before
// å†·å´æ—¶é—´ï¼š60ç§’ã€‚60ç§’åä¼šå°è¯•â€œå¤æ´»â€è¯¥æ¨¡å‹ã€‚
const COOLDOWN_DURATION = 60 * 1000;

/**
 * Get model pool based on model type with Smart Prioritization (æ™ºèƒ½ä¼˜å…ˆçº§)
 * 
 * Logic:
 * 1. Get the base pool (Already sorted by Quality/Priority)
 * 2. Filter out models that are currently in "Cool-down" (å‰”é™¤è¿˜åœ¨å†·å´çš„æ¨¡å‹)
 * 3. Return the filtered list (è¿”å›å¯ç”¨æ¨¡å‹åˆ—è¡¨)
 * 4. If ALL models are in cool-down, return the full list (Force retry) (å¦‚æœå…¨æŒ‚äº†ï¼Œå¼ºåˆ¶é‡è¯•)
 */
export function getModelPool(modelType: 'SMALL' | 'LARGE' | 'VISION' | 'CODE'): string[] {
    const pool = FREE_MODEL_POOLS[modelType];
    if (!pool) return [];

    const now = Date.now();

    // 1. Filter out models that are in cool-down
    // è¿‡æ»¤æ‰è¿˜åœ¨â€œå†·å´æœŸâ€çš„æ¨¡å‹
    const availableModels = pool.filter(model => {
        const lastFailure = rateLimitCoolDowns[model];
        // If never failed OR cool-down expired, it's available
        // å¦‚æœæ²¡æŒ‚è¿‡ï¼Œæˆ–è€…å·²ç»è¿‡äº†å†·å´æœŸï¼Œå°±å¯ç”¨
        if (!lastFailure) return true;

        const timeSinceFailure = now - lastFailure;
        if (timeSinceFailure > COOLDOWN_DURATION) {
            // Cool-down expired, remove from blacklist
            delete rateLimitCoolDowns[model];
            return true;
        }

        return false;
    });

    // 2. If we have available models, use them (They preserve the original priority order)
    // å¦‚æœæœ‰å¯ç”¨æ¨¡å‹ï¼ŒæŒ‰ä¼˜å…ˆçº§é¡ºåºè¿”å›
    if (availableModels.length > 0) {
        return availableModels;
    }

    // 3. If ALL models are in cool-down, reset everyone and return full pool
    // This prevents complete blockage if everything is failing temporarily
    // ç´§æ€¥æƒ…å†µï¼šæ‰€æœ‰äººéƒ½æŒ‚äº†ï¼Œé‚£å°±æ­»é©¬å½“æ´»é©¬åŒ»ï¼Œå…¨éƒ¨é‡è¯•
    return [...pool];
}

/**
 * Report a Rate Limit failure for a model
 * Call this when a model returns 429 or 402
 * æŠ¥å‘Šé™æµï¼šæŠŠæ¨¡å‹å…³è¿›â€œå°é»‘å±‹â€å†·å´
 */
export function reportRateLimit(modelName: string) {
    rateLimitCoolDowns[modelName] = Date.now();
    logger.warn(`âš ï¸ [OpenRouter Pool] Model [${modelName}] marked rate-limited (Cool-down for ${COOLDOWN_DURATION / 1000}s)`);
}

/**
 * Try models from pool with automatic fallback
 * Returns the first successful model name
 * å°è¯•æ¨¡å‹æ± ï¼šè‡ªåŠ¨å¤„ç†å›é€€
 */
export async function tryModelsFromPool<T>(
    runtime: IAgentRuntime,
    modelPool: string[],
    attemptFn: (modelName: string) => Promise<T>,
    context: string = 'operation'
): Promise<{ result: T; modelUsed: string }> {
    const errors: Array<{ model: string; error: string }> = [];

    // Smart logic: We don't rotate blindly. We try models in priority order.
    // If a model fails with Rate Limit, we mark it for cool-down.

    // Refresh pool to exclude cooled-down models (if this list came from getModelPool, it might be stale if we iterate long)
    // For now, we trust the input pool is fresh.

    for (const modelName of modelPool) {
        try {
            // Skip if recently marked as rate-limited (double check)
            // äºŒæ¬¡æ£€æŸ¥ï¼šé˜²æ­¢åœ¨å¾ªç¯è¿‡ç¨‹ä¸­è¢«å…¶ä»–è¯·æ±‚æ ‡è®°
            const lastFailure = rateLimitCoolDowns[modelName];
            if (lastFailure && (Date.now() - lastFailure < COOLDOWN_DURATION)) {
                continue;
            }

            logger.debug(`[OpenRouter Free Pool] Trying ${context} with model: ${modelName}`);
            const result = await attemptFn(modelName);
            logger.log(`[OpenRouter Free Pool] âœ… Success with model: ${modelName}`);

            // Success! Remove from cool-down if it was there (early parole)
            if (rateLimitCoolDowns[modelName]) {
                delete rateLimitCoolDowns[modelName];
            }

            return { result, modelUsed: modelName };
        } catch (error: unknown) {
            const errorMsg = error instanceof Error ? error.message : String(error);
            logger.warn(`[OpenRouter Free Pool] âš ï¸ Model ${modelName} failed: ${errorMsg}`);
            errors.push({ model: modelName, error: errorMsg });

            // Check if it's a rate limit error (429) or quota error
            // æ£€æŸ¥æ˜¯å¦æ˜¯é™æµé”™è¯¯
            if (errorMsg.includes('429') || errorMsg.includes('rate limit') || errorMsg.includes('quota') || errorMsg.includes('402')) {
                logger.warn(`[OpenRouter Free Pool] Rate limit hit on ${modelName}, marking for cool-down...`);
                reportRateLimit(modelName); // Mark for cool-down
                continue;
            }

            // For other errors, still try next model but log more details
            logger.debug(`[OpenRouter Free Pool] Error details: ${errorMsg}`);
            continue;
        }
    }

    // All models failed
    const errorSummary = errors.map(e => `${e.model}: ${e.error}`).join('\n');
    throw new Error(
        `[OpenRouter Free Pool] All free models exhausted for ${context}.\n` +
        `Tried ${modelPool.length} models:\n${errorSummary}\n` +
        `Suggestion: Wait a few minutes or consider using paid API keys.`
    );
}

/**
 * Check if a model name is from the free pool
 */
export function isFreeModel(modelName: string): boolean {
    return modelName.endsWith(':free');
}

/**
 * Get custom model from env or use free pool
 */
export function getModelOrPool(
    customModel: string | undefined,
    poolType: 'SMALL' | 'LARGE' | 'VISION'
): string[] {
    // If custom model is specified and it's a free model, use it as first priority
    if (customModel && isFreeModel(customModel)) {
        const pool = getModelPool(poolType);
        // Put custom model first, then other pool models (excluding duplicates)
        return [customModel, ...pool.filter(m => m !== customModel)];
    }

    // If custom model is specified but not free, use only that model
    if (customModel) {
        return [customModel];
    }

    // No custom model, use full free pool
    return getModelPool(poolType);
}
